{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3899d877",
   "metadata": {},
   "source": [
    "# Nerual network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f3d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, random, randrange\n",
    "from csv import reader\n",
    "from math import exp\n",
    "import os \n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39f260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/tianyi/Northeastern University/Machine Learning Final Project - Music Classification - Documents'\n",
    "myspace_mp3s_path = '%s/myspace_mp3s' % data_path\n",
    "metadata_path = '%s/metadata.json.gz' % myspace_mp3s_path\n",
    "genre_map_path = '%s/genre_map.pkl' % myspace_mp3s_path\n",
    "mfcc_path = '%s/audio_features/mfcc' % data_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725787e",
   "metadata": {},
   "source": [
    "# implement nerual network from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ccc56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs): \n",
    "    '''\n",
    "    Initialize a neural network\n",
    "    organize layers as arrays of dictionaries\n",
    "    '''\n",
    "    layer_input = []\n",
    "    for i in range(n_inputs): \n",
    "        layer_input.append({})\n",
    "    \n",
    "    # n hidden neurons for the hidden layer, and each neuron has n inputs + 1 weights, \n",
    "    # one for each input column in the dataset and another for the bias. \n",
    "    layer_hidden = []\n",
    "    for i in range(n_hidden): \n",
    "        w = []\n",
    "        b = random()\n",
    "        for j in range(n_inputs): \n",
    "            w.append(random())\n",
    "        layer_hidden.append({'w': w, 'b': b, 'o': 0, 'e': 0})\n",
    "        \n",
    "    #  n outputs neurons in the output layer that links to the hidden layer, \n",
    "    # each with n hidden + 1 weights. \n",
    "    layer_output = []\n",
    "    for i in range(n_outputs): \n",
    "        w = []\n",
    "        b = random()\n",
    "        for j in range(n_hidden): \n",
    "            w.append(random())\n",
    "        layer_output.append({'w': w, 'b': b, 'o': 0, 'e': 0})\n",
    "    \n",
    "    # treat the whole network as an array of layers\n",
    "    network = [layer_input, layer_hidden, layer_output]\n",
    "    \n",
    "    return network\n",
    "\n",
    "\n",
    "def activate(weights, inputs): \n",
    "    '''\n",
    "    Calculate neuron activation for an input\n",
    "    weights shape: n_neurons_hidden_layer x  n_neurons_inputs_layer\n",
    "    inputs shape: n_neurons_inputs_layer\n",
    "    result shape:  n_neurons_hidden_layer * 1\n",
    "    '''\n",
    "\n",
    "    res = []\n",
    "    for hid in range(len(weights)): \n",
    "        sum = 0.0\n",
    "        for inp in range(len(inputs)): \n",
    "            sum += inputs[inp] * weights[hid]['w'][inp]\n",
    "        \n",
    "        sum += weights[hid]['b']\n",
    "        \n",
    "        z = transfer(sum)\n",
    "        \n",
    "        res.append(z)\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "def transfer(activation): \n",
    "    '''\n",
    "    Transfer neuron activation\n",
    "    '''\n",
    "    return (1.0 / (1.0 + exp(-activation)));\n",
    "\n",
    "\n",
    "def forward_propagate(network, row): \n",
    "    '''\n",
    "    Forward propagate input to a network output\n",
    "    '''\n",
    "    \n",
    "    # input layer -> hidden layer\n",
    "    hidden_output = activate(network[1], row)\n",
    "    for i in range(len(hidden_output)): \n",
    "        network[1][i]['o'] = hidden_output[i]\n",
    "\n",
    "    \n",
    "    # hidden layer -> output layer\n",
    "    output = activate(network[2], hidden_output)\n",
    "    for i in range(len(output)): \n",
    "        network[2][i]['o'] = output[i]\n",
    "\n",
    "\n",
    "def transfer_derivative(output):\n",
    "    '''\n",
    "    Calculate the derivative of an neuron output\n",
    "    '''\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "\n",
    "def backward_propagate_error(network, expected):\n",
    "    '''\n",
    "    Backpropagate error and store in neurons\n",
    "    '''\n",
    "    error_output = []\n",
    "    for out in range(len(network[2])): \n",
    "        error = expected[out] - network[2][out]['o']\n",
    "        error_output.append(error)\n",
    "        network[2][out]['e'] = error\n",
    "        \n",
    "    for hid in range(len(network[1])): \n",
    "        error = 0.0\n",
    "        for out in range(len(network[2])): \n",
    "            error += error_output[out] * network[2][out]['w'][hid]\n",
    "            \n",
    "        error *= transfer_derivative(network[1][hid]['o'])\n",
    "        \n",
    "        network[1][hid]['e'] = error\n",
    "    \n",
    "\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "    '''\n",
    "    Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "    '''\n",
    "    (X_train, y_train) = train\n",
    "    (X_test, y_test) = test\n",
    "    n_inputs = len(X_train[0])\n",
    "    n_outputs = len(y_train[0])\n",
    "    network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "    \n",
    "    train_network(network, train, l_rate, n_epoch, n_outputs, test)\n",
    "    print('end of training')\n",
    "\n",
    "    # evaluate \n",
    "    pred_y = []\n",
    "    for X in X_test: \n",
    "        y = predict(network, X)\n",
    "        pred_y.append(y)\n",
    "        \n",
    "    \n",
    "    acc = accuracy_metric(y_test, pred_y)\n",
    "    print('final testing acc:', acc)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def update_weights(network, row, l_rate):\n",
    "    '''\n",
    "    Update network weights with error\n",
    "    '''\n",
    "    # Update the weights for the output layer\n",
    "    for out in range(len(network[2])): \n",
    "        for hid in range(len(network[1])): \n",
    "            w = network[2][out]['w'][hid]\n",
    "            w += (l_rate * network[2][out]['e'] * network[1][hid]['o'])\n",
    "            network[2][out]['w'][hid] = w\n",
    "            \n",
    "        b = network[2][out]['b']\n",
    "        b += (l_rate * network[2][out]['e'])\n",
    "        network[2][out]['b'] = b\n",
    "        \n",
    "    # Update the weights for the hidden layer\n",
    "    for hid in range(len(network[1])): \n",
    "        for inp in range(len(network[0])): \n",
    "            w = network[1][hid]['w'][inp]\n",
    "            w += (l_rate * network[1][hid]['e'] * row[inp])\n",
    "            network[1][hid]['w'][inp] = w\n",
    "        \n",
    "        b = network[1][hid]['b']\n",
    "        b += (l_rate * network[1][hid]['e'])\n",
    "        network[1][hid]['b'] = b\n",
    "\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs, test): \n",
    "    '''\n",
    "    Train a network for a fixed number of epochs\n",
    "    '''\n",
    "    (X_train, y_train) = train\n",
    "    (X_test, y_test) = test\n",
    "    \n",
    "    # updating the network for each row in the training dataset inside each epoch.\n",
    "    for epoch in range(n_epoch): \n",
    "        # evaluate for every 10 epoch: \n",
    "        if epoch % 10 == 0: \n",
    "            print('epoch:', epoch)\n",
    "\n",
    "            pred_y = []\n",
    "            for X in X_train: \n",
    "                y = predict(network, X)\n",
    "                pred_y.append(y)\n",
    "\n",
    "            acc = accuracy_metric(y_train, pred_y)\n",
    "            print('train acc:', acc)\n",
    "\n",
    "            pred_y = []\n",
    "            for X in X_test: \n",
    "                y = predict(network, X)\n",
    "                pred_y.append(y)\n",
    "\n",
    "            acc = accuracy_metric(y_test, pred_y)\n",
    "            print('test acc:', acc)\n",
    "\n",
    "        for i in range(len(X_train)): \n",
    "            X = X_train[i]\n",
    "            y = y_train[i]\n",
    "            forward_propagate(network, X)\n",
    "            backward_propagate_error(network, y)\n",
    "            update_weights(network, X, l_rate)\n",
    "\n",
    "\n",
    "def predict(network, row):\n",
    "    '''\n",
    "    Make a prediction with a network\n",
    "    '''\n",
    "    forward_propagate(network, row)\n",
    "    y = []\n",
    "    for out in range(len(network[2])): \n",
    "        output = network[2][out]['o']\n",
    "        y.append(output)\n",
    "        \n",
    "    return y\n",
    "\n",
    "\n",
    "def arg_max(output): \n",
    "    '''\n",
    "    find max element's index of array output\n",
    "    '''\n",
    "    max_index = 0\n",
    "    max = output[0]\n",
    "    for i in range(len(output)): \n",
    "        if output[i] > max: \n",
    "            max_o = output[i]\n",
    "            max_index = i\n",
    "\n",
    "    return max_index\n",
    "        \n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    '''\n",
    "    Calculate accuracy percentage\n",
    "    '''\n",
    "    total = len(actual)\n",
    "    correct = 0\n",
    "    for i in range(total): \n",
    "        \n",
    "        if arg_max(actual[i]) == arg_max(predicted[i]): \n",
    "            correct += 1\n",
    "         \n",
    "    acc = correct / total\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb34d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y):\n",
    "    '''\n",
    "    Shuffles x and y data. \n",
    "    '''\n",
    "    idx = np.arange(x.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def normalize_data(x):\n",
    "    '''\n",
    "    Normalizes x data. \n",
    "    '''\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "\n",
    "def get_mfccs(mfcc_path, genres, lab_idx, max_recs):\n",
    "    '''\n",
    "    Open and process mfcc and return as x and y arrays.\n",
    "    '''\n",
    "    \n",
    "    # save all x and y values\n",
    "    mfccs = []\n",
    "    y = []\n",
    "    \n",
    "    # loop over each genre we are working with\n",
    "    for genre in genres:\n",
    "        \n",
    "        # extract path to all song mfccs in current genre\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "\n",
    "        cnt = 0\n",
    "\n",
    "        # loop over each mfcc in current genre\n",
    "        for fn in os.listdir(genre_path): \n",
    "            \n",
    "            # get path to mfcc\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            \n",
    "            # load mfcc \n",
    "            # (20, 19518)\n",
    "            mfcc = np.load(fp) \n",
    "            # (20, )\n",
    "            # take mean\n",
    "            mfcc = np.mean(mfcc, axis=1)\n",
    "            mfccs.append(mfcc)\n",
    "            \n",
    "            # append target label to list\n",
    "            y.append(lab_idx[genre])\n",
    "            \n",
    "            # for creating balanced dataset\n",
    "            cnt += 1\n",
    "            if cnt == max_recs: \n",
    "                break\n",
    "           \n",
    "    # normalize data and create arrays\n",
    "    x = np.array(mfccs)\n",
    "    x = normalize_data(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return shuffle_data(x, y)\n",
    "\n",
    "\n",
    "SEED = 20211130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da58c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock 13158\n",
      "metal 8782\n",
      "alternative 8778\n",
      "rap 5906\n",
      "dance 5624\n",
      "pop 4684\n",
      "jazz 4552\n",
      "hip_hop 4526\n",
      "experimental 3686\n",
      "other 3544\n",
      "world 2225\n",
      "electronic 2127\n",
      "folk 1804\n",
      "punk 1729\n",
      "blues 1472\n",
      "ambient 1299\n",
      "reggae 1114\n",
      "goth 722\n",
      "acoustic 678\n",
      "country 533\n",
      "house 512\n",
      "classical 486\n",
      "spiritual 369\n",
      "oldies 248\n",
      "progressive 221\n",
      "funk 142\n",
      "easy_listening 131\n",
      "spoken_word 130\n",
      "bluegrass 48\n",
      "industrial 44\n",
      "showtunes 38\n",
      "disco 23\n"
     ]
    }
   ],
   "source": [
    "# genre counts (# samples per genre)\n",
    "genre_cts = {}\n",
    "for genre in os.listdir(mfcc_path):\n",
    "    genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "    genre_cts[genre] = len(os.listdir(genre_path))\n",
    "   \n",
    "# print counts for each genre\n",
    "for g in sorted(genre_cts, key=genre_cts.get, reverse=True):\n",
    "    print(g, genre_cts[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fe754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "['acoustic', 'alternative', 'ambient', 'bluegrass', 'blues', 'classical', 'country', 'dance', 'disco', 'easy_listening', 'electronic', 'experimental', 'folk', 'funk', 'goth', 'hip_hop', 'house', 'industrial', 'jazz', 'metal', 'oldies', 'other', 'pop', 'progressive', 'punk', 'rap', 'reggae', 'rock', 'showtunes', 'spiritual', 'spoken_word', 'world']\n",
      "lab_idx {'acoustic': 0, 'alternative': 1, 'ambient': 2, 'bluegrass': 3, 'blues': 4, 'classical': 5, 'country': 6, 'dance': 7, 'disco': 8, 'easy_listening': 9, 'electronic': 10, 'experimental': 11, 'folk': 12, 'funk': 13, 'goth': 14, 'hip_hop': 15, 'house': 16, 'industrial': 17, 'jazz': 18, 'metal': 19, 'oldies': 20, 'other': 21, 'pop': 22, 'progressive': 23, 'punk': 24, 'rap': 25, 'reggae': 26, 'rock': 27, 'showtunes': 28, 'spiritual': 29, 'spoken_word': 30, 'world': 31}\n",
      "min_recs 23\n",
      "shape: (736, 20) (736,)\n",
      "0 23\n",
      "1 23\n",
      "2 23\n",
      "3 23\n"
     ]
    }
   ],
   "source": [
    "genres = list(genre_cts.keys())\n",
    "all_genres =  list(genre_cts.keys())\n",
    "print(len(genres))\n",
    "# all_genres = ['jazz', 'reggae']\n",
    "print(all_genres)\n",
    "\n",
    "\n",
    "lab_idx = {g:i for i,g in enumerate(all_genres)}\n",
    "print('lab_idx', lab_idx)\n",
    "\n",
    "\n",
    "min_recs = min([genre_cts[g] for g in all_genres]) \n",
    "print('min_recs', min_recs)\n",
    "\n",
    "\n",
    "x, y = get_mfccs(mfcc_path, all_genres, lab_idx, min_recs)\n",
    "print('shape:', x.shape, y.shape)\n",
    "\n",
    "for i in [0, 1, 2, 3]: \n",
    "    print(i, np.count_nonzero(y == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f06d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train acc: 0.03231292517006803\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 10\n",
      "train acc: 0.034013605442176874\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 20\n",
      "train acc: 0.03231292517006803\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 30\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 40\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 50\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 60\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 70\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 80\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 90\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 100\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 110\n",
      "train acc: 0.030612244897959183\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 120\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.05405405405405406\n",
      "epoch: 130\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 140\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 150\n",
      "train acc: 0.05272108843537415\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 160\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 170\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 180\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 190\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 200\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 210\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 220\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 230\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 240\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 250\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 260\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 270\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 280\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 290\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 300\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 310\n",
      "train acc: 0.0663265306122449\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 320\n",
      "train acc: 0.06802721088435375\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 330\n",
      "train acc: 0.06972789115646258\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 340\n",
      "train acc: 0.07142857142857142\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 350\n",
      "train acc: 0.07142857142857142\n",
      "test acc: 0.05405405405405406\n",
      "epoch: 360\n",
      "train acc: 0.06972789115646258\n",
      "test acc: 0.05405405405405406\n",
      "epoch: 370\n",
      "train acc: 0.06972789115646258\n",
      "test acc: 0.05405405405405406\n",
      "epoch: 380\n",
      "train acc: 0.06972789115646258\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 390\n",
      "train acc: 0.06972789115646258\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 400\n",
      "train acc: 0.07142857142857142\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 410\n",
      "train acc: 0.07142857142857142\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 420\n",
      "train acc: 0.06972789115646258\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 430\n",
      "train acc: 0.06802721088435375\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 440\n",
      "train acc: 0.0663265306122449\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 450\n",
      "train acc: 0.0663265306122449\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 460\n",
      "train acc: 0.061224489795918366\n",
      "test acc: 0.05405405405405406\n",
      "epoch: 470\n",
      "train acc: 0.06292517006802721\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 480\n",
      "train acc: 0.06292517006802721\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 490\n",
      "train acc: 0.0663265306122449\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 500\n",
      "train acc: 0.06462585034013606\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 510\n",
      "train acc: 0.06462585034013606\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 520\n",
      "train acc: 0.06292517006802721\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 530\n",
      "train acc: 0.061224489795918366\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 540\n",
      "train acc: 0.06462585034013606\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 550\n",
      "train acc: 0.06292517006802721\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 560\n",
      "train acc: 0.061224489795918366\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 570\n",
      "train acc: 0.05952380952380952\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 580\n",
      "train acc: 0.05952380952380952\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 590\n",
      "train acc: 0.05952380952380952\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 600\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 610\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 620\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 630\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 640\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 650\n",
      "train acc: 0.05442176870748299\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 660\n",
      "train acc: 0.05272108843537415\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 670\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 680\n",
      "train acc: 0.04931972789115646\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 690\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.02702702702702703\n",
      "epoch: 700\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 710\n",
      "train acc: 0.04931972789115646\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 720\n",
      "train acc: 0.04931972789115646\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 730\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.033783783783783786\n",
      "epoch: 740\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 750\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 760\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 770\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.04054054054054054\n",
      "epoch: 780\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 790\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 800\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 810\n",
      "train acc: 0.05102040816326531\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 820\n",
      "train acc: 0.05272108843537415\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 830\n",
      "train acc: 0.05272108843537415\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 840\n",
      "train acc: 0.05272108843537415\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 850\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 860\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 870\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 880\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 890\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 900\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 910\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 920\n",
      "train acc: 0.05612244897959184\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 930\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 940\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 950\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 960\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 970\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 980\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "epoch: 990\n",
      "train acc: 0.05782312925170068\n",
      "test acc: 0.0472972972972973\n",
      "end of training\n",
      "final testing acc: 0.0472972972972973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0472972972972973"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(SEED)\n",
    "\n",
    "l_rate = 0.01\n",
    "n_epoch = 1000\n",
    "n_hidden = 128\n",
    "\n",
    "x = x.tolist()\n",
    "\n",
    "# convert y to one-hot\n",
    "y = y.tolist()\n",
    "def transfer_y(x):\n",
    "    tmp_y = []\n",
    "    modified_y = []\n",
    "    for i in range(len(genres)):\n",
    "        tmp_y.append(0)\n",
    "    modified_y = tmp_y\n",
    "    modified_y[x] = 1\n",
    "    \n",
    "    return modified_y\n",
    "\n",
    "for i in range(len(y)): \n",
    "    y[i] = transfer_y(y[i])\n",
    "\n",
    "# split into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)\n",
    "train = (X_train, y_train)\n",
    "test = (X_test, y_test)\n",
    "# train and evaluate\n",
    "back_propagation(train, test, l_rate, n_epoch, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87247ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
