{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "equipped-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, gzip, json, pickle, shutil, random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liked-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "myspace_mp3s_path = '%s/myspace_mp3s' % data_path\n",
    "metadata_path = '%s/metadata.json.gz' % myspace_mp3s_path\n",
    "genre_map_path = '%s/genre_map.pkl' % myspace_mp3s_path\n",
    "mfcc_path = '%s/audio_features/mfcc' % data_path\n",
    "\n",
    "#'rock', 'metal', 'dance', 'rap', 'pop', 'jazz', 'experimental', 'world', 'electronic', 'folk', 'punk', 'blues'\n",
    "binary_genres = ['metal', 'classical']\n",
    "\n",
    "lab_idx = {g:i for i,g in enumerate(binary_genres)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "successful-criterion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock 9535\n",
      "alternative 7056\n",
      "metal 6609\n",
      "dance 3620\n",
      "rap 3392\n",
      "pop 3216\n",
      "jazz 3118\n",
      "hip_hop 2764\n",
      "experimental 2624\n",
      "other 2548\n",
      "world 1611\n",
      "electronic 1468\n",
      "folk 1337\n",
      "punk 1315\n",
      "blues 1033\n",
      "ambient 977\n",
      "reggae 775\n",
      "goth 514\n",
      "acoustic 488\n",
      "country 365\n",
      "classical 357\n",
      "house 298\n",
      "spiritual 273\n",
      "progressive 157\n",
      "oldies 155\n",
      "funk 108\n",
      "spoken_word 101\n",
      "easy_listening 86\n",
      "bluegrass 40\n",
      "industrial 32\n",
      "showtunes 25\n",
      "disco 18\n"
     ]
    }
   ],
   "source": [
    "genre_cts = {}\n",
    "for genre in os.listdir(mfcc_path):\n",
    "    genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "    genre_cts[genre] = len(os.listdir(genre_path))\n",
    "    \n",
    "min_recs = min([genre_cts[g] for g in binary_genres])   \n",
    "\n",
    "for g in sorted(genre_cts, key=genre_cts.get, reverse=True):\n",
    "    print(g, genre_cts[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organized-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('46/std_1f69563352d19cb0132334cd0d3adeaf.mp3',\n",
       " {'song_name': 'big_yellow_moon',\n",
       "  'artist_name': 'bill_nelson',\n",
       "  'mp3_zipname': '46',\n",
       "  'mp3_filename': 'std_1f69563352d19cb0132334cd0d3adeaf.mp3',\n",
       "  'genres': ['rock', 'electronica', 'alternative']})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open(metadata_path, 'rt', encoding='utf-8') as fz:\n",
    "    metadata = json.load(fz)\n",
    "\n",
    "with open(genre_map_path, 'rb') as f:\n",
    "    genre_map = pickle.load(f)\n",
    "    \n",
    "#example metadata\n",
    "kys = list(metadata.keys())\n",
    "ky=kys[0]\n",
    "ky, metadata[ky]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "scenic-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9792.02380952381, 4837.91379828136)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mfcc_lengths(mfcc_path, genres, max_recs):\n",
    "    lens=[]\n",
    "    \n",
    "    for genre in binary_genres:\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "        ct = 0\n",
    "        for fn in os.listdir(genre_path):\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            mfcc = np.load(fp)\n",
    "            lens.append(mfcc.shape[1])\n",
    "            ct+=1\n",
    "            if ct>=min_recs:\n",
    "                break\n",
    "                \n",
    "    l = np.array(lens)\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "robust-subject",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.82483549e-06, 2.94161183e-06, 5.88322366e-06, 2.94161183e-05,\n",
       "        2.35328946e-05, 4.41241774e-05, 4.70657893e-05, 2.94161183e-05,\n",
       "        4.41241774e-05, 5.88322366e-05, 5.29490129e-05, 5.29490129e-05,\n",
       "        4.41241774e-05, 5.88322366e-05, 6.47154602e-05, 8.82483549e-05,\n",
       "        1.00014802e-04, 1.23547697e-04, 1.02956414e-04, 9.41315785e-05,\n",
       "        7.64819076e-05, 1.02956414e-04, 1.05898026e-04, 1.02956414e-04,\n",
       "        6.47154602e-05, 6.17738484e-05, 6.47154602e-05, 7.64819076e-05,\n",
       "        4.70657893e-05, 3.23577301e-05, 3.52993419e-05, 1.47080591e-05,\n",
       "        4.41241774e-05, 3.23577301e-05, 2.05912828e-05, 1.76496710e-05,\n",
       "        1.47080591e-05, 2.94161183e-06, 1.17664473e-05, 1.17664473e-05,\n",
       "        1.47080591e-05, 8.82483549e-06, 8.82483549e-06, 5.88322366e-06,\n",
       "        1.17664473e-05, 2.94161183e-06, 0.00000000e+00, 2.94161183e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.94161183e-06, 5.88322366e-06,\n",
       "        2.94161183e-06, 0.00000000e+00, 2.94161183e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.94161183e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.94161183e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.94161183e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.94161183e-06]),\n",
       " array([2.000000e+00, 4.781200e+02, 9.542400e+02, 1.430360e+03,\n",
       "        1.906480e+03, 2.382600e+03, 2.858720e+03, 3.334840e+03,\n",
       "        3.810960e+03, 4.287080e+03, 4.763200e+03, 5.239320e+03,\n",
       "        5.715440e+03, 6.191560e+03, 6.667680e+03, 7.143800e+03,\n",
       "        7.619920e+03, 8.096040e+03, 8.572160e+03, 9.048280e+03,\n",
       "        9.524400e+03, 1.000052e+04, 1.047664e+04, 1.095276e+04,\n",
       "        1.142888e+04, 1.190500e+04, 1.238112e+04, 1.285724e+04,\n",
       "        1.333336e+04, 1.380948e+04, 1.428560e+04, 1.476172e+04,\n",
       "        1.523784e+04, 1.571396e+04, 1.619008e+04, 1.666620e+04,\n",
       "        1.714232e+04, 1.761844e+04, 1.809456e+04, 1.857068e+04,\n",
       "        1.904680e+04, 1.952292e+04, 1.999904e+04, 2.047516e+04,\n",
       "        2.095128e+04, 2.142740e+04, 2.190352e+04, 2.237964e+04,\n",
       "        2.285576e+04, 2.333188e+04, 2.380800e+04, 2.428412e+04,\n",
       "        2.476024e+04, 2.523636e+04, 2.571248e+04, 2.618860e+04,\n",
       "        2.666472e+04, 2.714084e+04, 2.761696e+04, 2.809308e+04,\n",
       "        2.856920e+04, 2.904532e+04, 2.952144e+04, 2.999756e+04,\n",
       "        3.047368e+04, 3.094980e+04, 3.142592e+04, 3.190204e+04,\n",
       "        3.237816e+04, 3.285428e+04, 3.333040e+04, 3.380652e+04,\n",
       "        3.428264e+04, 3.475876e+04, 3.523488e+04, 3.571100e+04,\n",
       "        3.618712e+04, 3.666324e+04, 3.713936e+04, 3.761548e+04,\n",
       "        3.809160e+04, 3.856772e+04, 3.904384e+04, 3.951996e+04,\n",
       "        3.999608e+04, 4.047220e+04, 4.094832e+04, 4.142444e+04,\n",
       "        4.190056e+04, 4.237668e+04, 4.285280e+04, 4.332892e+04,\n",
       "        4.380504e+04, 4.428116e+04, 4.475728e+04, 4.523340e+04,\n",
       "        4.570952e+04, 4.618564e+04, 4.666176e+04, 4.713788e+04,\n",
       "        4.761400e+04]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = get_mfcc_lengths(mfcc_path, binary_genres, min_recs)\n",
    "\n",
    "print('Mean mfcc length: %.4f, std: %.4f' % (l.mean(), l.std())) #9792.02380952381, 4837.91379828136\n",
    "\n",
    "plt.hist(l, bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-laugh",
   "metadata": {},
   "source": [
    "### Try different ways of dealing with the varying mfcc lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "successful-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = np.load('%s/acoustic/msp_1_std_1b7ee19baed6ae4ea7332a60db0bcb4f.npy' % mfcc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "clean-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.8108591e+02,  1.2224055e+02,  2.8064362e+01,  3.1553217e+01,\n",
       "         1.5940080e+01,  1.3792233e+01,  4.4775543e+00,  5.4401940e-01,\n",
       "        -8.0222225e+00, -9.0548048e+00, -7.3031354e+00, -8.1062689e+00,\n",
       "        -9.4938993e+00, -7.5461569e+00, -9.5483360e+00, -1.1156130e+01,\n",
       "        -1.2253296e+01, -7.0494881e+00, -7.5009913e+00, -6.9211936e+00],\n",
       "       [ 8.6951828e+01,  2.9867422e+01,  1.9666704e+01,  1.4971158e+01,\n",
       "         1.1757245e+01,  8.2338200e+00,  8.2472515e+00,  7.4393983e+00,\n",
       "         7.9877319e+00,  1.0237029e+01,  8.3215666e+00,  7.6278958e+00,\n",
       "         8.1165676e+00,  7.5231209e+00,  7.4042001e+00,  6.7408314e+00,\n",
       "         6.5452747e+00,  6.6313405e+00,  7.7863317e+00,  7.5268083e+00],\n",
       "       [-2.0438838e-01,  1.9405127e+00,  8.4137917e-01,  7.3870349e-01,\n",
       "         7.7184796e-01,  5.1357436e-01,  1.5301127e+00,  9.4353080e-01,\n",
       "         3.4467864e-01,  2.7901173e-02, -4.7985554e-02, -1.4419651e-01,\n",
       "         7.4904442e-02, -1.5321231e-01,  2.5043797e-01,  5.4659796e-01,\n",
       "         2.1384959e+00,  1.0369496e+00,  5.6265497e-01,  5.4365230e-01],\n",
       "       [ 7.2641796e-01, -1.0781850e+00, -7.8138596e-01,  4.7336259e-01,\n",
       "        -7.4200726e-01, -7.6374947e-03, -8.4771901e-01, -1.3314392e-01,\n",
       "        -2.1730286e-01,  1.8870550e-01,  1.2844105e-01,  1.4315043e-01,\n",
       "         6.3976988e-02,  2.5204366e-02, -1.0298510e-01,  7.9656824e-02,\n",
       "         4.8126605e-01,  2.8682962e-01, -1.4631346e-01,  2.4007763e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([mfcc.mean(axis=1), mfcc.std(axis=1), stats.kurtosis(mfcc, axis=1), stats.skew(mfcc, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "optical-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y):\n",
    "    idx = np.arange(x.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def normalize_data(x):\n",
    "    return (x-x.mean())/x.std()\n",
    "\n",
    "\n",
    "def get_col_stats(mfcc_path, genres, lab_idx, max_recs):\n",
    "    mfccs = []\n",
    "    y=[]\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "        ct = 0\n",
    "        \n",
    "        for fn in os.listdir(genre_path):\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            \n",
    "            mfcc = np.load(fp)\n",
    "            mfccs.append(np.hstack([mfcc.mean(axis=1), \n",
    "                                    mfcc.std(axis=1), \n",
    "                                    stats.kurtosis(mfcc, axis=1), \n",
    "                                    stats.skew(mfcc, axis=1)]))\n",
    "            \n",
    "            y.append(lab_idx[genre])\n",
    "            \n",
    "            ct+=1\n",
    "            if ct>=max_recs:\n",
    "                break\n",
    "                \n",
    "    x = np.array(mfccs)\n",
    "    x = normalize_data(x)\n",
    "    \n",
    "    y = np.array(y)\n",
    "    \n",
    "    return shuffle_data(x, y)\n",
    "\n",
    "                \n",
    "def truncate_cols(mfcc_path, genres, lab_idx, col_len, max_recs):\n",
    "    mfccs = []\n",
    "    y=[]\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_path = '%s/%s' % (mfcc_path, genre)\n",
    "        ct = 0\n",
    "        \n",
    "        for fn in os.listdir(genre_path):\n",
    "            fp = '%s/%s' % (genre_path, fn)\n",
    "            \n",
    "            mfcc = np.load(fp)[:,:col_len]\n",
    "            mfccs.append(np.pad(mfcc, ((0,0),(0,col_len-mfcc.shape[1])), 'constant'))\n",
    "            \n",
    "            y.append(lab_idx[genre])\n",
    "            \n",
    "            ct+=1\n",
    "            if ct>=max_recs:\n",
    "                break\n",
    "                \n",
    "    x = np.array(mfccs)\n",
    "    y = np.array(y)\n",
    "                \n",
    "    return shuffle_data(x, y)\n",
    "\n",
    "\n",
    "def svd_reduce(x, n_components=100):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    x = svd.fit_transform(x.reshape(x.shape[0], -1))\n",
    "    print(x.shape, svd.explained_variance_ratio_.sum())\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "global-quarter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((714, 80), (714,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_col_stats(mfcc_path, binary_genres, lab_idx, min_recs)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spanish-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = x.shape[0]//5\n",
    "x_train, x_test, y_train, y_test = x[num_test:], x[:num_test], y[num_test:], y[:num_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-vacation",
   "metadata": {},
   "source": [
    "### Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-passenger",
   "metadata": {},
   "source": [
    "#### Col_stats, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "younger-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "atmospheric-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        72\n",
      "           1       0.95      0.86      0.90        70\n",
      "\n",
      "    accuracy                           0.91       142\n",
      "   macro avg       0.91      0.91      0.91       142\n",
      "weighted avg       0.91      0.91      0.91       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1.0, max_iter=1000)\n",
    "\n",
    "clf = log_reg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-patent",
   "metadata": {},
   "source": [
    "#### Col_stats, LinearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "robust-alaska",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        72\n",
      "           1       0.93      0.90      0.91        70\n",
      "\n",
      "    accuracy                           0.92       142\n",
      "   macro avg       0.92      0.92      0.92       142\n",
      "weighted avg       0.92      0.92      0.92       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lin_svm = LinearSVC(C=1.0, loss='hinge', max_iter=10000)\n",
    "\n",
    "clf = lin_svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-powder",
   "metadata": {},
   "source": [
    "#### Col_stats, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alive-riding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84        72\n",
      "           1       0.84      0.81      0.83        70\n",
      "\n",
      "    accuracy                           0.83       142\n",
      "   macro avg       0.83      0.83      0.83       142\n",
      "weighted avg       0.83      0.83      0.83       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1.0, kernel='sigmoid', gamma='scale')\n",
    "\n",
    "clf = svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#poly, degree 2: 0.89\n",
    "#poly, degree 3: 0.88\n",
    "#rbf: 0.9\n",
    "#sigmoid: 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-trace",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "prepared-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        72\n",
      "           1       0.84      0.84      0.84        70\n",
      "\n",
      "    accuracy                           0.85       142\n",
      "   macro avg       0.85      0.85      0.85       142\n",
      "weighted avg       0.85      0.85      0.85       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10), solver='adam', max_iter=2500)\n",
    "\n",
    "clf = mlp.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#adam\n",
    "#hid 3 : 0.91\n",
    "#hid 5 : 0.92\n",
    "#hid 10 : 0.92\n",
    "#hid 20 : 0.91\n",
    "#hid 50 : 0.91\n",
    "#hid 100 : 0.91\n",
    "#hid 200 : 0.91\n",
    "#hid 500 : 0.90\n",
    "#hid 5,5 : 0.88\n",
    "#hid 10,5 : 0.89\n",
    "#hid 20,10 : 0.9\n",
    "#hid 100,50 : 0.89\n",
    "\n",
    "#sgd always did a bit worse than adam, lbfgs did even worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-endorsement",
   "metadata": {},
   "source": [
    "####  = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "improved-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87        72\n",
      "           1       0.85      0.90      0.88        70\n",
      "\n",
      "    accuracy                           0.87       142\n",
      "   macro avg       0.87      0.87      0.87       142\n",
      "weighted avg       0.87      0.87      0.87       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "    \n",
    "clf = qda.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-harvard",
   "metadata": {},
   "source": [
    "#### Custom network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "confident-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicClassifier(nn.Module):\n",
    "    def __init__(self, num_in, num_out):\n",
    "        super(MusicClassifier, self).__init__()\n",
    "        self.layer_1 = nn.Linear(num_in, 256)\n",
    "        self.layer_2 = nn.Linear(256, 256)\n",
    "        self.layer_out = nn.Linear(256, num_out)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(256)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "blond-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = MusicClassifier(x_train.shape[1], 1)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "coordinate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model, optimizer, criterion, batch_size, epochs, device):\n",
    "    x_batches = [x[i*batch_size:(i+1)*batch_size] for i in range((x.shape[0]//batch_size) + 1)]\n",
    "    y_batches = [y[i*batch_size:(i+1)*batch_size] for i in range((x.shape[0]//batch_size) + 1)]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        \n",
    "        idx = list(range(len(x_batches)))\n",
    "        random.shuffle(idx)\n",
    "        x_batches = [x_batches[i] for i in idx]\n",
    "        y_batches = [y_batches[i] for i in idx]\n",
    "        \n",
    "        for x_batch, y_batch in zip(x_batches, y_batches):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(x_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        print('Epoch %d\\tLoss: %.8f\\tAcc: %.8f' % (epoch, epoch_loss/len(x_batches), epoch_acc/len(x_batches)))\n",
    "        \n",
    "    return model\n",
    "        \n",
    "        \n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    cor = (y_pred == y_test).sum().float()\n",
    "    acc = cor/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "def test(x_test, y_test, model):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test)\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred = torch.round(y_pred).cpu().numpy()\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    y_preds = [a.squeeze().tolist() for a in y_preds]\n",
    "    y_preds = [int(y) for y in y_preds[0]]\n",
    "    \n",
    "    print(classification_report(y_test.tolist(), y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "spiritual-philadelphia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\tLoss: 0.38558594\tAcc: 80.50000000\n",
      "Epoch 2\tLoss: 0.24455492\tAcc: 90.16666667\n",
      "Epoch 3\tLoss: 0.20625146\tAcc: 91.50000000\n",
      "Epoch 4\tLoss: 0.18040086\tAcc: 92.33333333\n",
      "Epoch 5\tLoss: 0.16888884\tAcc: 93.33333333\n",
      "Epoch 6\tLoss: 0.15121719\tAcc: 94.33333333\n",
      "Epoch 7\tLoss: 0.14243192\tAcc: 93.66666667\n",
      "Epoch 8\tLoss: 0.13041150\tAcc: 94.83333333\n",
      "Epoch 9\tLoss: 0.12027192\tAcc: 95.50000000\n",
      "Epoch 10\tLoss: 0.11081885\tAcc: 96.16666667\n",
      "Epoch 11\tLoss: 0.09795913\tAcc: 96.16666667\n",
      "Epoch 12\tLoss: 0.08834397\tAcc: 96.50000000\n",
      "Epoch 13\tLoss: 0.08013438\tAcc: 97.16666667\n",
      "Epoch 14\tLoss: 0.07279375\tAcc: 98.00000000\n",
      "Epoch 15\tLoss: 0.06219166\tAcc: 98.33333333\n",
      "Epoch 16\tLoss: 0.05496892\tAcc: 98.50000000\n",
      "Epoch 17\tLoss: 0.04779060\tAcc: 98.50000000\n",
      "Epoch 18\tLoss: 0.03963955\tAcc: 98.83333333\n",
      "Epoch 19\tLoss: 0.03275208\tAcc: 99.00000000\n",
      "Epoch 20\tLoss: 0.02934855\tAcc: 99.33333333\n",
      "Epoch 21\tLoss: 0.02517277\tAcc: 99.66666667\n",
      "Epoch 22\tLoss: 0.01930327\tAcc: 99.66666667\n",
      "Epoch 23\tLoss: 0.01619601\tAcc: 99.83333333\n",
      "Epoch 24\tLoss: 0.01431931\tAcc: 99.66666667\n",
      "Epoch 25\tLoss: 0.01138207\tAcc: 100.00000000\n",
      "Epoch 26\tLoss: 0.00998047\tAcc: 100.00000000\n",
      "Epoch 27\tLoss: 0.00804609\tAcc: 100.00000000\n",
      "Epoch 28\tLoss: 0.00629245\tAcc: 100.00000000\n",
      "Epoch 29\tLoss: 0.00513088\tAcc: 100.00000000\n",
      "Epoch 30\tLoss: 0.00457320\tAcc: 100.00000000\n",
      "Epoch 31\tLoss: 0.00378446\tAcc: 100.00000000\n",
      "Epoch 32\tLoss: 0.00315890\tAcc: 100.00000000\n",
      "Epoch 33\tLoss: 0.00306702\tAcc: 100.00000000\n",
      "Epoch 34\tLoss: 0.00256693\tAcc: 100.00000000\n",
      "Epoch 35\tLoss: 0.00240525\tAcc: 100.00000000\n",
      "Epoch 36\tLoss: 0.00210957\tAcc: 100.00000000\n",
      "Epoch 37\tLoss: 0.00199302\tAcc: 100.00000000\n",
      "Epoch 38\tLoss: 0.00168007\tAcc: 100.00000000\n",
      "Epoch 39\tLoss: 0.00171330\tAcc: 100.00000000\n",
      "Epoch 40\tLoss: 0.00153966\tAcc: 100.00000000\n",
      "Epoch 41\tLoss: 0.00150839\tAcc: 100.00000000\n",
      "Epoch 42\tLoss: 0.00135102\tAcc: 100.00000000\n",
      "Epoch 43\tLoss: 0.00125999\tAcc: 100.00000000\n",
      "Epoch 44\tLoss: 0.00120213\tAcc: 100.00000000\n",
      "Epoch 45\tLoss: 0.00118312\tAcc: 100.00000000\n",
      "Epoch 46\tLoss: 0.00108242\tAcc: 100.00000000\n",
      "Epoch 47\tLoss: 0.00103838\tAcc: 100.00000000\n",
      "Epoch 48\tLoss: 0.00097893\tAcc: 100.00000000\n",
      "Epoch 49\tLoss: 0.00091765\tAcc: 100.00000000\n",
      "Epoch 50\tLoss: 0.00084062\tAcc: 100.00000000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "model = train_model(torch.from_numpy(x), torch.from_numpy(y).float(), \n",
    "            model, optimizer, criterion, batch_size, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "western-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        72\n",
      "         1.0       1.00      1.00      1.00        70\n",
      "\n",
      "    accuracy                           1.00       142\n",
      "   macro avg       1.00      1.00      1.00       142\n",
      "weighted avg       1.00      1.00      1.00       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(torch.from_numpy(x_test).to(device), torch.from_numpy(y_test).float().to(device), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-settle",
   "metadata": {},
   "source": [
    "#### CNN for padded raw mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
